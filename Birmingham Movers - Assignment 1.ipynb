{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d29eeda",
   "metadata": {},
   "source": [
    "# Birmingham Movers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979a3e8",
   "metadata": {},
   "source": [
    "# web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a6394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.superpages.com/birmingham-al/movers?page=1\n",
      "Scraping page 2: https://www.superpages.com/birmingham-al/movers?page=2\n",
      "Scraping page 3: https://www.superpages.com/birmingham-al/movers?page=3\n",
      "Scraping page 4: https://www.superpages.com/birmingham-al/movers?page=4\n",
      "Scraping page 5: https://www.superpages.com/birmingham-al/movers?page=5\n",
      "Scraping page 6: https://www.superpages.com/birmingham-al/movers?page=6\n",
      "Scraping page 7: https://www.superpages.com/birmingham-al/movers?page=7\n",
      "Data successfully scraped and saved to 'movers.json' and 'movers.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Function to extract cleaned domain from a URL\n",
    "def get_cleaned_domain(url):\n",
    "    if not url:\n",
    "        return ''\n",
    "    url = url.strip().replace('http://', '').replace('https://', '').replace('www.', '')\n",
    "    return url.split('/')[0]\n",
    "\n",
    "# Base URL of the page to scrape\n",
    "base_url = \"https://www.superpages.com/birmingham-al/movers\"\n",
    "\n",
    "# Initialize a list to store extracted data\n",
    "data_list = []\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    listings = soup.select('.organic .result')  # Adjusted selector\n",
    "\n",
    "    for listing in listings:\n",
    "        name_element = listing.select_one('.business-name')\n",
    "        name = name_element.get_text(strip=True) if name_element else 'N/A'\n",
    "\n",
    "        domain_element = listing.select_one('.weblink-button')\n",
    "        domain = get_cleaned_domain(domain_element['href']) if domain_element and domain_element.has_attr('href') else 'N/A'\n",
    "\n",
    "        phone_element = listing.select_one('.phone')\n",
    "        phone = phone_element.get_text(strip=True) if phone_element else 'N/A'\n",
    "        phone = re.sub(r'\\D', '', phone)  # Remove any non-numeric characters\n",
    "\n",
    "        address_element = listing.select_one('.adr')\n",
    "        address = address_element.get_text(strip=True) if address_element else 'N/A'\n",
    "        \n",
    "        keyword_elements = listing.select('.categories a')\n",
    "        keywords = [keyword.get_text(strip=True) for keyword in keyword_elements] if keyword_elements else []\n",
    "\n",
    "\n",
    "        data_list.append({\n",
    "            'Name': name,\n",
    "            'Cleaned Domain': domain,\n",
    "            'Phone Number': phone,\n",
    "            'Address': address,\n",
    "            'Keywords': keywords\n",
    "        })\n",
    "\n",
    "# Loop through the pages until no more results are found\n",
    "page_number = 1\n",
    "while True:\n",
    "    page_url = f\"{base_url}?page={page_number}\"\n",
    "    print(f\"Scraping page {page_number}: {page_url}\")\n",
    "    previous_data_length = len(data_list)\n",
    "    scrape_page(page_url)\n",
    "    \n",
    "    # Break the loop if no new data was added\n",
    "    if len(data_list) == previous_data_length:\n",
    "        break\n",
    "\n",
    "    page_number += 1\n",
    "\n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save the data to JSON and CSV formats\n",
    "df.to_json('movers.json', orient='records', indent=4)\n",
    "df.to_csv('movers.csv', index=False)\n",
    "\n",
    "print(\"Data successfully scraped and saved to 'movers.json' and 'movers.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f1c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f5edc00",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe2fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fe7149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cleaned Domain</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Latitude Movers</td>\n",
       "      <td>newlatitudemovers.com</td>\n",
       "      <td>2058553737</td>\n",
       "      <td>130 Industrial Drive, Birmingham, AL, 35211</td>\n",
       "      <td>['Movers', 'Relocation Service']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oakdale Moving &amp; Storage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8446814827</td>\n",
       "      <td>Serving the Birmingham Area</td>\n",
       "      <td>['Movers', 'Movers-Commercial &amp; Industrial', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIR 7 SEAS Transport Logistics Inc</td>\n",
       "      <td>air7seas.com</td>\n",
       "      <td>8884048124</td>\n",
       "      <td>Serving the Birmingham Area</td>\n",
       "      <td>['Movers', 'Customs Consultants', 'Moving Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Will Transport It</td>\n",
       "      <td>wewilltransportit.com</td>\n",
       "      <td>8443157733</td>\n",
       "      <td>Serving the Birmingham Area</td>\n",
       "      <td>['Movers', 'Boat Equipment &amp; Supplies', 'Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good Moves Moving Systems Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2054108527</td>\n",
       "      <td>5821 Walnut Grove Rd, Birmingham, AL, 35215</td>\n",
       "      <td>['Movers', 'Movers &amp; Full Service Storage', 'M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name         Cleaned Domain  Phone Number  \\\n",
       "0                 New Latitude Movers  newlatitudemovers.com    2058553737   \n",
       "1            Oakdale Moving & Storage                    NaN    8446814827   \n",
       "2  AIR 7 SEAS Transport Logistics Inc           air7seas.com    8884048124   \n",
       "3                We Will Transport It  wewilltransportit.com    8443157733   \n",
       "4       Good Moves Moving Systems Inc                    NaN    2054108527   \n",
       "\n",
       "                                       Address  \\\n",
       "0  130 Industrial Drive, Birmingham, AL, 35211   \n",
       "1                  Serving the Birmingham Area   \n",
       "2                  Serving the Birmingham Area   \n",
       "3                  Serving the Birmingham Area   \n",
       "4  5821 Walnut Grove Rd, Birmingham, AL, 35215   \n",
       "\n",
       "                                            Keywords  \n",
       "0                   ['Movers', 'Relocation Service']  \n",
       "1  ['Movers', 'Movers-Commercial & Industrial', '...  \n",
       "2  ['Movers', 'Customs Consultants', 'Moving Serv...  \n",
       "3  ['Movers', 'Boat Equipment & Supplies', 'Trans...  \n",
       "4  ['Movers', 'Movers & Full Service Storage', 'M...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('movers.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a05b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Name            173 non-null    object\n",
      " 1   Cleaned Domain  89 non-null     object\n",
      " 2   Phone Number    173 non-null    int64 \n",
      " 3   Address         173 non-null    object\n",
      " 4   Keywords        173 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d095c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Cleaned Domain    84\n",
       "Phone Number       0\n",
       "Address            0\n",
       "Keywords           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbf12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name              0.000000\n",
       "Cleaned Domain    0.485549\n",
       "Phone Number      0.000000\n",
       "Address           0.000000\n",
       "Keywords          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c50ad",
   "metadata": {},
   "source": [
    "**There are 48% of  null values present in the cleaned domain column \n",
    "but I am not dropping the null values since it may affect the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73df74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32549712",
   "metadata": {},
   "source": [
    "**there are no duplicate values present in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586d7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
