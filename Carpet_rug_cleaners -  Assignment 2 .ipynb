{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5babaa4",
   "metadata": {},
   "source": [
    "# Carpet_rug_cleaners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb812de",
   "metadata": {},
   "source": [
    "# web scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9615b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=1\n",
      "Scraping page 2: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=2\n",
      "Scraping page 3: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=3\n",
      "Scraping page 4: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=4\n",
      "Scraping page 5: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=5\n",
      "Scraping page 6: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=6\n",
      "Scraping page 7: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=7\n",
      "Scraping page 8: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=8\n",
      "Scraping page 9: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=9\n",
      "Scraping page 10: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=10\n",
      "Scraping page 11: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=11\n",
      "Scraping page 12: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=12\n",
      "Scraping page 13: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=13\n",
      "Scraping page 14: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=14\n",
      "Scraping page 15: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=15\n",
      "Scraping page 16: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=16\n",
      "Scraping page 17: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=17\n",
      "Scraping page 18: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=18\n",
      "Scraping page 19: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=19\n",
      "Scraping page 20: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=20\n",
      "Scraping page 21: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=21\n",
      "Scraping page 22: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=22\n",
      "Scraping page 23: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=23\n",
      "Scraping page 24: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=24\n",
      "Scraping page 25: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=25\n",
      "Scraping page 26: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=26\n",
      "Scraping page 27: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=27\n",
      "Scraping page 28: https://www.superpages.com/new-york-ny/carpet-rug-cleaners?page=28\n",
      "Data successfully scraped and saved to 'carpet_rug_cleaners.json' and 'carpet_rug_cleaners.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Function to extract cleaned domain from a URL\n",
    "def get_cleaned_domain(url):\n",
    "    if not url:\n",
    "        return ''\n",
    "    url = url.strip().replace('http://', '').replace('https://', '').replace('www.', '')\n",
    "    return url.split('/')[0]\n",
    "\n",
    "# Base URL of the page to scrape\n",
    "base_url = \"https://www.superpages.com/new-york-ny/carpet-rug-cleaners\"\n",
    "\n",
    "# Initialize a list to store extracted data\n",
    "data_list = []\n",
    "\n",
    "# Function to scrape a single page\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    listings = soup.select('.organic .result')  # Adjusted selector\n",
    "\n",
    "    for listing in listings:\n",
    "        name_element = listing.select_one('.business-name')\n",
    "        name = name_element.get_text(strip=True) if name_element else 'N/A'\n",
    "\n",
    "        domain_element = listing.select_one('.weblink-button')\n",
    "        domain = get_cleaned_domain(domain_element['href']) if domain_element and domain_element.has_attr('href') else 'N/A'\n",
    "\n",
    "        phone_element = listing.select_one('.phone')\n",
    "        phone = phone_element.get_text(strip=True) if phone_element else 'N/A'\n",
    "        phone = re.sub(r'\\D', '', phone)  # Remove any non-numeric characters\n",
    "\n",
    "        address_element = listing.select_one('.adr')\n",
    "        address = address_element.get_text(strip=True) if address_element else 'N/A'\n",
    "        \n",
    "        keyword_elements = listing.select('.categories a')\n",
    "        keywords = [keyword.get_text(strip=True) for keyword in keyword_elements] if keyword_elements else []\n",
    "\n",
    "\n",
    "        data_list.append({\n",
    "            'Name': name,\n",
    "            'Cleaned Domain': domain,\n",
    "            'Phone Number': phone,\n",
    "            'Address': address,\n",
    "            'Keywords': keywords\n",
    "        })\n",
    "\n",
    "# Loop through the pages until no more results are found\n",
    "page_number = 1\n",
    "while True:\n",
    "    page_url = f\"{base_url}?page={page_number}\"\n",
    "    print(f\"Scraping page {page_number}: {page_url}\")\n",
    "    previous_data_length = len(data_list)\n",
    "    scrape_page(page_url)\n",
    "    \n",
    "    # Break the loop if no new data was added\n",
    "    if len(data_list) == previous_data_length:\n",
    "        break\n",
    "\n",
    "    page_number += 1\n",
    "\n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save the data to JSON and CSV formats\n",
    "df.to_json('carpet_rug_cleaners.json', orient='records', indent=4)\n",
    "df.to_csv('carpet_rug_cleaners.csv', index=False)\n",
    "\n",
    "print(\"Data successfully scraped and saved to 'carpet_rug_cleaners.json' and 'carpet_rug_cleaners.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae394c3",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd90540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25577342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cleaned Domain</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Address</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue Chip Building Maintenance Inc</td>\n",
       "      <td>bluechipclean.com</td>\n",
       "      <td>2125640100</td>\n",
       "      <td>242 W 30th St Rm 700, New York, NY, 10001</td>\n",
       "      <td>['Carpet &amp; Rug Cleaners', 'Janitorial Service'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delmont Carpet Cleaning Inc</td>\n",
       "      <td>delmontcleanny.com</td>\n",
       "      <td>9292434945</td>\n",
       "      <td>1636 3rd Ave, New York, NY, 10128</td>\n",
       "      <td>['Carpet &amp; Rug Cleaners', 'Upholstery Cleaners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Pro Cleaning &amp; Restoration</td>\n",
       "      <td>allprorestoration.com</td>\n",
       "      <td>9143726244</td>\n",
       "      <td>13 Haven St, Elmsford, NY, 10523</td>\n",
       "      <td>['Carpet &amp; Rug Cleaners', 'Cleaning Contractor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delmont Carpet Cleaning Inc</td>\n",
       "      <td>api.superpages.com</td>\n",
       "      <td>6464026590</td>\n",
       "      <td>New York, NY, 10128</td>\n",
       "      <td>['Carpet &amp; Rug Cleaners']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleantex - New York</td>\n",
       "      <td>cleantexny.com</td>\n",
       "      <td>2122831200</td>\n",
       "      <td>3711 48th Ave, Long Island City, NY, 11101</td>\n",
       "      <td>['Carpet &amp; Rug Cleaners', 'Cleaning Contractor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name         Cleaned Domain  Phone Number  \\\n",
       "0  Blue Chip Building Maintenance Inc      bluechipclean.com    2125640100   \n",
       "1         Delmont Carpet Cleaning Inc     delmontcleanny.com    9292434945   \n",
       "2      All Pro Cleaning & Restoration  allprorestoration.com    9143726244   \n",
       "3         Delmont Carpet Cleaning Inc     api.superpages.com    6464026590   \n",
       "4                 Cleantex - New York         cleantexny.com    2122831200   \n",
       "\n",
       "                                      Address  \\\n",
       "0   242 W 30th St Rm 700, New York, NY, 10001   \n",
       "1           1636 3rd Ave, New York, NY, 10128   \n",
       "2            13 Haven St, Elmsford, NY, 10523   \n",
       "3                         New York, NY, 10128   \n",
       "4  3711 48th Ave, Long Island City, NY, 11101   \n",
       "\n",
       "                                            Keywords  \n",
       "0  ['Carpet & Rug Cleaners', 'Janitorial Service'...  \n",
       "1  ['Carpet & Rug Cleaners', 'Upholstery Cleaners...  \n",
       "2  ['Carpet & Rug Cleaners', 'Cleaning Contractor...  \n",
       "3                          ['Carpet & Rug Cleaners']  \n",
       "4  ['Carpet & Rug Cleaners', 'Cleaning Contractor...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('carpet_rug_cleaners.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a838293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 783 entries, 0 to 782\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Name            783 non-null    object\n",
      " 1   Cleaned Domain  385 non-null    object\n",
      " 2   Phone Number    783 non-null    int64 \n",
      " 3   Address         783 non-null    object\n",
      " 4   Keywords        783 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 30.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a436877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                0\n",
       "Cleaned Domain    398\n",
       "Phone Number        0\n",
       "Address             0\n",
       "Keywords            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47feb6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name              0.000000\n",
       "Cleaned Domain    0.508301\n",
       "Phone Number      0.000000\n",
       "Address           0.000000\n",
       "Keywords          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2715a",
   "metadata": {},
   "source": [
    "**There is almost 50% data missing in cleaned domain column but not going to drop it because it will affect the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc8ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a3af9",
   "metadata": {},
   "source": [
    "**There is no duplicate values present in the data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a437a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
